{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入模型所必須要的相依套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定相關參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = \"bert-base-cased\"\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 160\n",
    "EPOCHS = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "TOKENIZER = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義相關function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    將資料集轉換為後續data DataLoader 需求的 pytorch Dataset形式\n",
    "    Convert movie review dataframe into torch dataset instance\n",
    "    \"\"\"\n",
    "    def __init__(self, comments, targets, max_len):\n",
    "        self.comments = comments\n",
    "        self.targets = targets\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        comment = str(self.comments[item])\n",
    "        target = self.targets[item]\n",
    "        encoding = TOKENIZER.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'comment': comment,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(dataframe, max_len, batch_size):\n",
    "    \"\"\"\n",
    "    將pytorch Dataset形式資料集包裝為data DataLoader\n",
    "    convert dataset to pytorch dataloader format object\n",
    "    \"\"\"\n",
    "    dataset = ReviewDataset(\n",
    "        comments=list(dataframe.comment.to_numpy()),\n",
    "        targets=list(dataframe.score.to_numpy()),\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT電影影評評分回歸模型的主體\n",
    "    Bert sentiment regression model for review sentiment analyzer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SentimentRegressor, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,\n",
    "                data_loader,\n",
    "                loss_fn,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                n_examples):\n",
    "    \"\"\"\n",
    "    電影評論分類器的訓練主流程\n",
    "    Main training process of bert sentiment classifier\n",
    "    \"\"\"\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for _d in data_loader:\n",
    "        input_ids = _d[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = _d[\"attention_mask\"].to(DEVICE)\n",
    "        targets = _d[\"targets\"].to(DEVICE)\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model,\n",
    "               data_loader,\n",
    "               loss_fn,\n",
    "               n_examples):\n",
    "    \"\"\"\n",
    "    電影評論分類器的訓練時每個epoch評估訓練效能主流程\n",
    "    Main evaluate process in training of bert sentiment classifier\n",
    "    \"\"\"\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = d[\"attention_mask\"].to(DEVICE)\n",
    "            targets = d[\"targets\"].to(DEVICE)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取先求有data_extract.py所處理完的資料，並將資料區分成train(49500筆)與validate(500筆)兩個部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.read_json(\"./data/train.json\")\n",
    "TRAIN = TRAIN.sample(frac=1).reset_index(drop=True)\n",
    "VAL = pd.read_json(\"./data/test.json\")\n",
    "VAL = VAL.sample(frac=1).reset_index(drop=True)\n",
    "TRAIN = TRAIN.append(VAL[500:]).reset_index(drop=True)\n",
    "VAL = VAL.iloc[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立訓練所需物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = SentimentRegressor()\n",
    "MODEL.to(DEVICE)\n",
    "\n",
    "TRAIN_DATA_LOADER = create_data_loader(TRAIN, MAX_LEN, BATCH_SIZE)\n",
    "VAL_DATA_LOADER = create_data_loader(VAL, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "OPTIMIZER = AdamW(MODEL.parameters(), lr=2e-5, correct_bias=False)\n",
    "TOTAL_STEPS = len(TRAIN_DATA_LOADER) * EPOCHS\n",
    "SCHEDULER = get_linear_schedule_with_warmup(\n",
    "    OPTIMIZER,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=TOTAL_STEPS\n",
    ")\n",
    "LOSS_FN = nn.MSELoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_LOSS = 100000000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_loss = train_epoch(\n",
    "        MODEL,\n",
    "        TRAIN_DATA_LOADER,\n",
    "        LOSS_FN,\n",
    "        OPTIMIZER,\n",
    "        SCHEDULER,\n",
    "        len(TRAIN)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss}')\n",
    "\n",
    "    val_loss = eval_model(\n",
    "        MODEL,\n",
    "        VAL_DATA_LOADER,\n",
    "        LOSS_FN,\n",
    "        len(VAL)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss}')\n",
    "    print()\n",
    "\n",
    "    if val_loss > BEST_LOSS:\n",
    "        MODEL.bert.save_pretrained(\"./\")\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
